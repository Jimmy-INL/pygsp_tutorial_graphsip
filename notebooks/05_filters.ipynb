{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Filters\n",
    "\n",
    "To filter signals on graphs, we need to define filters. They are represented in the toolbox by the [`pygsp.filters.Filter` class](https://pygsp.readthedocs.io/en/stable/reference/filters.html). Filters are usually defined in the spectral domain. Given the transfer function\n",
    "\n",
    "**TODO**\n",
    "* look at <https://pygsp.readthedocs.io/en/stable/tutorials/intro.html#filters>\n",
    "* localization as great tool to visualize filters in the vertex domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pygsp import graphs, filters\n",
    "from additional_utils import compute_cheby_coeff, get_approx_filter\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Heat diffusion\n",
    "\n",
    "**TODO**: show that this is heat diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = graphs.Sensor(seed=42)\n",
    "G1.compute_fourier_basis()\n",
    "G2 = graphs.Ring(N=100)\n",
    "G2.compute_fourier_basis()\n",
    "G2.set_coordinates('line1D')\n",
    "\n",
    "TAUS = [0, 5, 100]\n",
    "DELTA = 10\n",
    "\n",
    "fig, axes = plt.subplots(len(TAUS), 3, figsize=(15, 6))\n",
    "\n",
    "for i, tau in enumerate(TAUS):\n",
    "    g1 = filters.Heat(G1, tau)\n",
    "    g2 = filters.Heat(G2, tau)\n",
    "    \n",
    "    y = g1.localize(DELTA).squeeze()\n",
    "    G1.plot_signal(y, ax=axes[i, 0])\n",
    "    axes[i, 0].set_axis_off()\n",
    "    axes[i, 0].text(0, -0.2, '$y^T L y = {:.2f}$'.format(y.T @ G1.L @ y))\n",
    "    \n",
    "    G2.plot_signal(g2.localize(G2.N//2), ax=axes[i, 2])\n",
    "    \n",
    "    g1.plot(ax=axes[i, 1])\n",
    "    axes[i, 1].set_xlabel('')\n",
    "    axes[i, 1].set_ylabel('')\n",
    "    text = r'$\\hat{{g}}(\\lambda) = \\exp \\left( \\frac{{-{{{}}} \\lambda}}{{\\lambda_{{max}}}} \\right)$'.format(tau)\n",
    "    axes[i, 1].text(6, 0.5, text, fontsize=15)\n",
    "    \n",
    "axes[0, 0].set_title('$y = \\hat{{g}}(L) \\delta_{{{}}}$: localized on sensor'.format(DELTA))\n",
    "axes[0, 1].set_title('$\\hat{g}(\\lambda)$: filter defined in the spectral domain')\n",
    "axes[0, 2].set_title('$y = \\hat{{g}}(L) \\delta_{{{}}}$: localized on ring graph'.format(G2.N//2))\n",
    "axes[-1, 1].set_xlabel(\"$\\lambda$: laplacian's eigenvalues / graph frequencies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Example of denoising\n",
    "Let's define a low-pass filter\n",
    "$$g(\\lambda) = \\frac{1}{1+\\tau\\lambda}$$\n",
    "Given a noisy version of a smooth signal $x_\\text{noisy}$, one can denoise it with the low-pass filter $g$:\n",
    "$$ x_\\text{denoised} = \\mathbf{U}g(\\mathbf{\\Lambda})\\mathbf{U}^\\top x_{\\text{noisy}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the graph:\n",
    "G = graphs.Logo()\n",
    "G.compute_fourier_basis()\n",
    "\n",
    "# the filter:\n",
    "tau = 1\n",
    "def g(x):\n",
    "    return 1. / (1. + tau * x)\n",
    "g = filters.Filter(G, g)\n",
    "\n",
    "# the noisy signal:\n",
    "x = np.zeros(G.N)\n",
    "x[G.info['idx_g']-1] = -1\n",
    "x[G.info['idx_s']-1] = 0\n",
    "x[G.info['idx_p']-1] = 1\n",
    "rs = np.random.RandomState(42)\n",
    "x_noisy = x + rs.uniform(-1, 1, size=G.N)\n",
    "\n",
    "# the denoised signal:\n",
    "x_denoised = g.filter(x_noisy, method='exact')\n",
    "\n",
    "# and... plot:\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "G.plot_signal(x_noisy, vertex_size=30, ax=axes[0])\n",
    "_ = axes[0].set_title('Noisy signal')\n",
    "axes[0].set_axis_off()\n",
    "G.plot_signal(x_denoised, vertex_size=30, ax=axes[1])\n",
    "_ = axes[1].set_title('Cleaned signal')\n",
    "axes[1].set_axis_off()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Polynomial approximation\n",
    "Let us approximate the filter $$g(x) = \\frac{1}{1+x}$$ on the interval $[0,\\lambda_N]$ by a Chebychev polynomial of order $m$:\n",
    "$$g(x) \\simeq \\sum_{k=0}^m \\alpha_k x^k=p(x),$$\n",
    "such that the exact filtering can be approximated by a polynomial in $\\mathbf{L}$:\n",
    "\\begin{align}\n",
    "x_{\\text{filtered}}&=\\mathbf{U}g(\\mathbf{\\Lambda})\\mathbf{U}^\\top x\\\\\n",
    "&\\simeq \\mathbf{U}p(\\mathbf{\\Lambda})\\mathbf{U}^\\top x\\\\\n",
    "&=\\mathbf{U}\\sum_{k=0}^m \\alpha_k \\mathbf{\\Lambda}^k\\mathbf{U}^\\top x\\\\\n",
    "&=\\sum_{k=0}^m \\alpha_k \\mathbf{L}^k x\n",
    "\\end{align}\n",
    "Note that computing $\\sum_{k=0}^m \\alpha_k \\mathbf{L}^k x$ takes only $m$ matrix-vector multiplication and costs thus $\\mathcal{O}(m|E|)$ with $|E|$ the number of edges of the graph (compared to the $\\mathcal{O}(N^3)$ necessary operations just to diagonalize $\\mathbf{L}$ for the exact computation!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = lambda x: 1 / (1 + x)\n",
    "filt_g = filters.Filter(G, g)\n",
    "c = filters.approximations.compute_cheby_coeff(filt_g, m=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_approx = get_approx_filter(c)\n",
    "\n",
    "x = np.arange(0, G.lmax, (G.lmax) / 1000)\n",
    "plt.figure()\n",
    "plt.plot(x, g(x))\n",
    "plt.hold\n",
    "plt.plot(x, np.squeeze(filt_approx((x-(G.lmax/2)) / (G.lmax/2))))\n",
    "plt.legend(['original filter', 'polynomial approximation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "G.compute_fourier_basis(recompute = True) #just to measure time\n",
    "x_denoised_exact = filt_g.filter(x_noisy, method='exact')\n",
    "time_exact_filter = time.time() - start_time\n",
    "start_time = time.time()\n",
    "G.estimate_lmax(recompute = True) #just to measure time\n",
    "x_denoised_cheby = filt_g.filter(x_noisy, method='chebyshev', order=m)\n",
    "time_cheby_filter = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "G.plot_signal(x_denoised_exact, vertex_size=30, ax=axes[0])\n",
    "_ = axes[0].set_title('Exact denoising')\n",
    "axes[0].set_axis_off()\n",
    "G.plot_signal(x_denoised_cheby, vertex_size=30, ax=axes[1])\n",
    "_ = axes[1].set_title('Chebyshev approx')\n",
    "axes[1].set_axis_off()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The max error is ' + str(np.max(np.abs(x_denoised_exact-x_denoised_cheby))))\n",
    "print('The mean energy of the error is ' + str((np.sum((x_denoised_exact - x_denoised_cheby)**2)/G.N)))\n",
    "\n",
    "print('The computation time for exact filtering was ' + str(time_exact_filter))\n",
    "print('The computation time for approx filtering was ' + str(time_cheby_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Precision-Efficiency trade-off of the polynomial approximation\n",
    "Illustrate the precision vs computation time trade-off of the Chebyshev polynomial approximation, as the order of the polynomial changes. How about with the ideal low-pass```g = lambda x: x <= cut_off_freq```?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Filterbanks\n",
    "\n",
    "**TODO**:\n",
    "* popular filterbanks\n",
    "* tight vs non-tight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = graphs.Ring(N=20)\n",
    "G.estimate_lmax()\n",
    "G.set_coordinates('line1D')\n",
    "g = filters.HalfCosine(G)\n",
    "s = g.localize(G.N // 2)\n",
    "g.plot()\n",
    "G.plot_signal(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Approximations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "* Approximation with Chebyshev polynomials.\n",
    "* Show computational advantage.\n",
    "* Show how it smoothes the original filterbank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Exercise\n",
    "\n",
    "Solve the following problem using a graph filter:\n",
    "$$\\mathbf{x}^* = \\operatorname*{arg\\,min}_{\\mathbf{x} \\in \\mathbb{R}^N} \\|\\mathbf{y} - \\mathbf{x}\\|_2^2 + \\alpha \\mathbf{x}^\\intercal \\mathbf{L} \\mathbf{x},$$\n",
    "where $y$ is the observed signal, $\\alpha$ is an hyper-parameter which controls the trade-off between the data fidelity term and the smoothness prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
